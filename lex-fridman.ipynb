{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            guest                    title  \\\n",
       "0   1      Max Tegmark                 Life 3.0   \n",
       "1   2    Christof Koch            Consciousness   \n",
       "2   3    Steven Pinker  AI in the Age of Reason   \n",
       "3   4    Yoshua Bengio            Deep Learning   \n",
       "4   5  Vladimir Vapnik     Statistical Learning   \n",
       "\n",
       "                                                text  \n",
       "0  As part of MIT course 6S099, Artificial Genera...  \n",
       "1  As part of MIT course 6S099 on artificial gene...  \n",
       "2  You've studied the human mind, cognition, lang...  \n",
       "3  What difference between biological neural netw...  \n",
       "4  The following is a conversation with Vladimir ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "archivo_csv = 'podcastdata_dataset.csv.zip'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i in range(len(df)):\n",
    "    tokens.append(df['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oraciones\n",
    "len(df['text'][0].split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Palabras\n",
    "for i in range(len(df)):\n",
    "    len(df['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10217"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = str(df[df['id'] == 2]['text'].values[0])\n",
    "len(texto.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc(texto):\n",
    "    return len(texto.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wc'] = df['text'].apply(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws(texto):\n",
    "    return texto.split('.'),len(texto.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text sentence', 'ws']] = df['text'].apply(lambda x: pd.Series(ws(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wc</th>\n",
       "      <th>text sentence</th>\n",
       "      <th>ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>13424</td>\n",
       "      <td>[As part of MIT course 6S099, Artificial Gener...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "      <td>10217</td>\n",
       "      <td>[As part of MIT course 6S099 on artificial gen...</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "      <td>5989</td>\n",
       "      <td>[You've studied the human mind, cognition, lan...</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "      <td>5993</td>\n",
       "      <td>[What difference between biological neural net...</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "      <td>6374</td>\n",
       "      <td>[The following is a conversation with Vladimir...</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            guest                    title  \\\n",
       "0   1      Max Tegmark                 Life 3.0   \n",
       "1   2    Christof Koch            Consciousness   \n",
       "2   3    Steven Pinker  AI in the Age of Reason   \n",
       "3   4    Yoshua Bengio            Deep Learning   \n",
       "4   5  Vladimir Vapnik     Statistical Learning   \n",
       "\n",
       "                                                text     wc  \\\n",
       "0  As part of MIT course 6S099, Artificial Genera...  13424   \n",
       "1  As part of MIT course 6S099 on artificial gene...  10217   \n",
       "2  You've studied the human mind, cognition, lang...   5989   \n",
       "3  What difference between biological neural netw...   5993   \n",
       "4  The following is a conversation with Vladimir ...   6374   \n",
       "\n",
       "                                       text sentence   ws  \n",
       "0  [As part of MIT course 6S099, Artificial Gener...  611  \n",
       "1  [As part of MIT course 6S099 on artificial gen...  499  \n",
       "2  [You've studied the human mind, cognition, lan...  292  \n",
       "3  [What difference between biological neural net...  311  \n",
       "4  [The following is a conversation with Vladimir...  514  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390883"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ws'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    episode_id = row['id']\n",
    "    for idx, sentence in enumerate(row['text sentence'], start=1):\n",
    "        rows.append({'ep_id': episode_id, 'sentence_id': idx, 'text': sentence})\n",
    "\n",
    "df_modelado = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ep_id  sentence_id                                               text\n",
      "0        1            1  As part of MIT course 6S099, Artificial Genera...\n",
      "1        1            2                      He is a professor here at MIT\n",
      "2        1            3   He's a physicist, spent a large part of his c...\n",
      "3        1            4   But he's also studied and delved into the ben...\n",
      "4        1            5   Amongst many other things, he is the cofounde...\n",
      "..     ...          ...                                                ...\n",
      "606      1          607   So speaking of software that nobody understan...\n",
      "607      1          608   But what are your thoughts on deep learning? ...\n",
      "608      1          609   What are your thoughts about the promise limi...\n",
      "609      1          610   One of them is when you look at the human bra...\n",
      "610      1          611                                                   \n",
      "\n",
      "[611 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "oraciones_episodio_1 = df_modelado[df_modelado['ep_id'] == 1]\n",
    "print(oraciones_episodio_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenización: Convertir frases en listas de palabras\n",
    "df_modelado['tokens'] = df_modelado['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# 2. Entrenamiento de Word2Vec\n",
    "# Crear una lista de listas de palabras (tokens) para entrenar Word2Vec\n",
    "sentences = df_modelado['tokens'].tolist()\n",
    "\n",
    "# Entrenar el modelo Word2Vec\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\glenn\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\glenn\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\glenn\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\glenn\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\glenn\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "# 3. Obtener embeddings para cada frase\n",
    "# Función para promediar los vectores de palabras en cada oración\n",
    "def obtener_embedding(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return sum(vectors) / len(vectors)  # Promedio de vectores\n",
    "    else:\n",
    "        return [0] * model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelado['embedding'] = df_modelado['tokens'].apply(lambda x: obtener_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>[as, part, of, mit, course, 6s099, ,, artifici...</td>\n",
       "      <td>[0.1613159, -0.3011463, 0.39027765, -0.3895926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He is a professor here at MIT</td>\n",
       "      <td>[he, is, a, professor, here, at, mit]</td>\n",
       "      <td>[0.826645, 0.31023565, -0.112632684, -1.0861, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>He's a physicist, spent a large part of his c...</td>\n",
       "      <td>[he, 's, a, physicist, ,, spent, a, large, par...</td>\n",
       "      <td>[-0.31360346, 0.19543181, -0.21830845, -0.4296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>But he's also studied and delved into the ben...</td>\n",
       "      <td>[but, he, 's, also, studied, and, delved, into...</td>\n",
       "      <td>[-0.15041693, -0.65338206, 0.15157872, -0.7465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Amongst many other things, he is the cofounde...</td>\n",
       "      <td>[amongst, many, other, things, ,, he, is, the,...</td>\n",
       "      <td>[-0.1738735, -0.47554147, 0.004054738, -0.7451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390878</th>\n",
       "      <td>325</td>\n",
       "      <td>1727</td>\n",
       "      <td>It's the beginning</td>\n",
       "      <td>[it, 's, the, beginning]</td>\n",
       "      <td>[0.2809784, -0.029861778, 0.40465134, -0.88828...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390879</th>\n",
       "      <td>325</td>\n",
       "      <td>1728</td>\n",
       "      <td>It's not the whole story by any means, but it...</td>\n",
       "      <td>[it, 's, not, the, whole, story, by, any, mean...</td>\n",
       "      <td>[-0.1577536, -0.8891785, 0.23679683, -0.607141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390880</th>\n",
       "      <td>325</td>\n",
       "      <td>1729</td>\n",
       "      <td>Where's state stored of the system? Is it in ...</td>\n",
       "      <td>[where, 's, state, stored, of, the, system, ?,...</td>\n",
       "      <td>[-0.43209156, -0.59306145, 0.8185598, -0.91418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390881</th>\n",
       "      <td>325</td>\n",
       "      <td>1730</td>\n",
       "      <td>So there are chemical networks</td>\n",
       "      <td>[so, there, are, chemical, networks]</td>\n",
       "      <td>[0.2585203, -1.0753529, 0.54024637, -0.9459638...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390882</th>\n",
       "      <td>325</td>\n",
       "      <td>1731</td>\n",
       "      <td>So for example, gene regulatory networks, rig...</td>\n",
       "      <td>[so, for, example, ,, gene, regulatory, networ...</td>\n",
       "      <td>[-0.16053124, -0.22479251, 0.4757672, -0.92713...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390883 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ep_id  sentence_id                                               text  \\\n",
       "0           1            1  As part of MIT course 6S099, Artificial Genera...   \n",
       "1           1            2                      He is a professor here at MIT   \n",
       "2           1            3   He's a physicist, spent a large part of his c...   \n",
       "3           1            4   But he's also studied and delved into the ben...   \n",
       "4           1            5   Amongst many other things, he is the cofounde...   \n",
       "...       ...          ...                                                ...   \n",
       "390878    325         1727                                 It's the beginning   \n",
       "390879    325         1728   It's not the whole story by any means, but it...   \n",
       "390880    325         1729   Where's state stored of the system? Is it in ...   \n",
       "390881    325         1730                     So there are chemical networks   \n",
       "390882    325         1731   So for example, gene regulatory networks, rig...   \n",
       "\n",
       "                                                   tokens  \\\n",
       "0       [as, part, of, mit, course, 6s099, ,, artifici...   \n",
       "1                   [he, is, a, professor, here, at, mit]   \n",
       "2       [he, 's, a, physicist, ,, spent, a, large, par...   \n",
       "3       [but, he, 's, also, studied, and, delved, into...   \n",
       "4       [amongst, many, other, things, ,, he, is, the,...   \n",
       "...                                                   ...   \n",
       "390878                           [it, 's, the, beginning]   \n",
       "390879  [it, 's, not, the, whole, story, by, any, mean...   \n",
       "390880  [where, 's, state, stored, of, the, system, ?,...   \n",
       "390881               [so, there, are, chemical, networks]   \n",
       "390882  [so, for, example, ,, gene, regulatory, networ...   \n",
       "\n",
       "                                                embedding  \n",
       "0       [0.1613159, -0.3011463, 0.39027765, -0.3895926...  \n",
       "1       [0.826645, 0.31023565, -0.112632684, -1.0861, ...  \n",
       "2       [-0.31360346, 0.19543181, -0.21830845, -0.4296...  \n",
       "3       [-0.15041693, -0.65338206, 0.15157872, -0.7465...  \n",
       "4       [-0.1738735, -0.47554147, 0.004054738, -0.7451...  \n",
       "...                                                   ...  \n",
       "390878  [0.2809784, -0.029861778, 0.40465134, -0.88828...  \n",
       "390879  [-0.1577536, -0.8891785, 0.23679683, -0.607141...  \n",
       "390880  [-0.43209156, -0.59306145, 0.8185598, -0.91418...  \n",
       "390881  [0.2585203, -1.0753529, 0.54024637, -0.9459638...  \n",
       "390882  [-0.16053124, -0.22479251, 0.4757672, -0.92713...  \n",
       "\n",
       "[390883 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embeddings = np.array(df_modelado['embedding'].tolist())\n",
    "\n",
    "# Número de clusters \n",
    "n_clusters = 5\n",
    "\n",
    "# Aplicar K-Means\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_modelado['cluster'] = kmeans.fit_predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>[as, part, of, mit, course, 6s099, ,, artifici...</td>\n",
       "      <td>[0.1613159, -0.3011463, 0.39027765, -0.3895926...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He is a professor here at MIT</td>\n",
       "      <td>[he, is, a, professor, here, at, mit]</td>\n",
       "      <td>[0.826645, 0.31023565, -0.112632684, -1.0861, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>He's a physicist, spent a large part of his c...</td>\n",
       "      <td>[he, 's, a, physicist, ,, spent, a, large, par...</td>\n",
       "      <td>[-0.31360346, 0.19543181, -0.21830845, -0.4296...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>But he's also studied and delved into the ben...</td>\n",
       "      <td>[but, he, 's, also, studied, and, delved, into...</td>\n",
       "      <td>[-0.15041693, -0.65338206, 0.15157872, -0.7465...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Amongst many other things, he is the cofounde...</td>\n",
       "      <td>[amongst, many, other, things, ,, he, is, the,...</td>\n",
       "      <td>[-0.1738735, -0.47554147, 0.004054738, -0.7451...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1</td>\n",
       "      <td>607</td>\n",
       "      <td>So speaking of software that nobody understan...</td>\n",
       "      <td>[so, speaking, of, software, that, nobody, und...</td>\n",
       "      <td>[0.06536546, -0.47318673, 0.18265536, -0.70092...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>But what are your thoughts on deep learning? ...</td>\n",
       "      <td>[but, what, are, your, thoughts, on, deep, lea...</td>\n",
       "      <td>[-0.16667138, -0.6664908, 0.2817549, -0.438010...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1</td>\n",
       "      <td>609</td>\n",
       "      <td>What are your thoughts about the promise limi...</td>\n",
       "      <td>[what, are, your, thoughts, about, the, promis...</td>\n",
       "      <td>[0.09421101, -0.8972975, 0.37856245, -0.598907...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>One of them is when you look at the human bra...</td>\n",
       "      <td>[one, of, them, is, when, you, look, at, the, ...</td>\n",
       "      <td>[-0.04121255, -0.57340884, 0.22704954, -0.8795...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1</td>\n",
       "      <td>611</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ep_id  sentence_id                                               text  \\\n",
       "0        1            1  As part of MIT course 6S099, Artificial Genera...   \n",
       "1        1            2                      He is a professor here at MIT   \n",
       "2        1            3   He's a physicist, spent a large part of his c...   \n",
       "3        1            4   But he's also studied and delved into the ben...   \n",
       "4        1            5   Amongst many other things, he is the cofounde...   \n",
       "..     ...          ...                                                ...   \n",
       "606      1          607   So speaking of software that nobody understan...   \n",
       "607      1          608   But what are your thoughts on deep learning? ...   \n",
       "608      1          609   What are your thoughts about the promise limi...   \n",
       "609      1          610   One of them is when you look at the human bra...   \n",
       "610      1          611                                                      \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [as, part, of, mit, course, 6s099, ,, artifici...   \n",
       "1                [he, is, a, professor, here, at, mit]   \n",
       "2    [he, 's, a, physicist, ,, spent, a, large, par...   \n",
       "3    [but, he, 's, also, studied, and, delved, into...   \n",
       "4    [amongst, many, other, things, ,, he, is, the,...   \n",
       "..                                                 ...   \n",
       "606  [so, speaking, of, software, that, nobody, und...   \n",
       "607  [but, what, are, your, thoughts, on, deep, lea...   \n",
       "608  [what, are, your, thoughts, about, the, promis...   \n",
       "609  [one, of, them, is, when, you, look, at, the, ...   \n",
       "610                                                 []   \n",
       "\n",
       "                                             embedding  cluster  \n",
       "0    [0.1613159, -0.3011463, 0.39027765, -0.3895926...        1  \n",
       "1    [0.826645, 0.31023565, -0.112632684, -1.0861, ...        1  \n",
       "2    [-0.31360346, 0.19543181, -0.21830845, -0.4296...        1  \n",
       "3    [-0.15041693, -0.65338206, 0.15157872, -0.7465...        1  \n",
       "4    [-0.1738735, -0.47554147, 0.004054738, -0.7451...        1  \n",
       "..                                                 ...      ...  \n",
       "606  [0.06536546, -0.47318673, 0.18265536, -0.70092...        1  \n",
       "607  [-0.16667138, -0.6664908, 0.2817549, -0.438010...        4  \n",
       "608  [0.09421101, -0.8972975, 0.37856245, -0.598907...        1  \n",
       "609  [-0.04121255, -0.57340884, 0.22704954, -0.8795...        1  \n",
       "610  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        1  \n",
       "\n",
       "[611 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelado[df_modelado['ep_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  But my dad, he pushed me against the car and go, what do you mean you might know something about this? I said, dad, I don't for sure, but, and I would probably all crying, but, and I don't, I doubt if I was crying yet\n",
      "Cluster 1:  If you end up with a list of like, well, these are things we never want to see, that list leaks, and after the passage of some time, certainly couldn't be done today, but after the passage of some time, lots and lots of people in academic labs going all the way down to the high school level are in a position to make it overly simplistic, hit print on a genome and have the virus bearing that genome pop out on the other end and you've got something to worry about, but in general, computational biology I think is incredibly important, particularly because the crushing majority of work that people are doing with the protein folding problem and other things are about creating therapeutics, about creating things that will help us live better, live longer, thrive, be more well, and so forth, and the protein folding problem is a monstrous computational challenge that we seem to make just the most glacial project on, I'm sorry, progress on for years and years, but I think there's a biannual competition I think for which people tackle the protein folding problem, and Deep Mind's entrant both two years ago, like in 2018 and 2020, ruled the field, and so protein folding is an unbelievably important thing if you want to start thinking about therapeutics because it's the folding of the protein that tells us where the channels and the receptors and everything else are on that protein, and it's from that precise model, if we can get to a precise model, that you can start barraging it again in silicone with thousands, tens of thousands, millions of potential therapeutics and see what resolves the problems, the shortcomings that a misshapen protein, for instance, somebody with cystic fibrosis, how might we treat that? So I see nothing but good in that\n",
      "Cluster 2:  It's just, it's such a great privilege to exist that, that yeah, it's just, I think that's the scary part\n",
      "Cluster 3:  Yeah\n",
      "Cluster 4:  Or that same person could say that'll be longterm healthy for the platform or for the platform's influence on society outside of the platform, right? And it, you know, it's easy for me to sit here and say these things, but conceptually I do not think that these are kind of totally or should, they shouldn't be kind of completely alien ideas, right? That, you know, you could try things like this and it wouldn't be, you know, we wouldn't have to invent entirely new science to do it because if we're all already embedded in some metric space and there's a notion of distance between you and me and every other, every piece of content, then, you know, we know exactly, you know, the same model that tells, you know, dictates how to make me really happy also tells how to make me as unhappy as possible as well\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Obtener los centroides de cada cluster\n",
    "centroides = kmeans.cluster_centers_\n",
    "\n",
    "# Función para encontrar la similitud coseno entre un vector y el centroide de un cluster\n",
    "def obtener_similitud_con_centroide(embedding, centroide):\n",
    "    return cosine_similarity([embedding], [centroide])[0][0]\n",
    "\n",
    "# Crear un diccionario para almacenar las oraciones más representativas de cada cluster\n",
    "oraciones_topico = {}\n",
    "\n",
    "# Iterar sobre cada cluster y encontrar las oraciones más cercanas al centroide\n",
    "for cluster_id in range(n_clusters):\n",
    "    # Obtener las oraciones en este cluster\n",
    "    oraciones_cluster = df_modelado[df_modelado['cluster'] == cluster_id]\n",
    "    \n",
    "    # Obtener los embeddings de estas oraciones\n",
    "    embeddings_cluster = np.array(oraciones_cluster['embedding'].tolist())\n",
    "    \n",
    "    # Calcular la similitud coseno entre cada embedding y el centroide del cluster\n",
    "    similitudes = [obtener_similitud_con_centroide(embedding, centroides[cluster_id]) for embedding in embeddings_cluster]\n",
    "    \n",
    "    # Encontrar el índice de la oración más cercana al centroide\n",
    "    indice_max_similitud = np.argmax(similitudes)\n",
    "    \n",
    "    # Obtener la oración más representativa y asociarla con el cluster\n",
    "    oracion_representativa = oraciones_cluster.iloc[indice_max_similitud]['text']\n",
    "    \n",
    "    # Guardar la oración más representativa en el diccionario\n",
    "    oraciones_topico[cluster_id] = oracion_representativa\n",
    "\n",
    "# Mostrar las oraciones más representativas de cada cluster (tópico)\n",
    "for cluster_id, oracion in oraciones_topico.items():\n",
    "    print(f\"Cluster {cluster_id}: {oracion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Crear un DataFrame con los tópicos y sus oraciones representativas\n",
    "topicos_df = pd.DataFrame(list(oraciones_topico.items()), columns=['Cluster', 'Oracion Representativa'])\n",
    "\n",
    "def obtener_embedding_busqueda(clave, modelo):\n",
    "    tokens = clave.split()\n",
    "    vectores = [modelo.wv[word] for word in tokens if word in modelo.wv]\n",
    "    if len(vectores) > 0:\n",
    "        return np.mean(vectores, axis=0)\n",
    "    else:\n",
    "        return np.zeros(modelo.vector_size)\n",
    "\n",
    "# Función para realizar la búsqueda\n",
    "def buscar_por_topico(clave, modelo, df_modelado, top_n=5):\n",
    "    # Obtener el embedding de las palabras clave\n",
    "    embedding_busqueda = obtener_embedding_busqueda(clave, modelo)\n",
    "    \n",
    "    # Calcular la similitud coseno entre el embedding de búsqueda y los embeddings de las oraciones\n",
    "    embeddings_oraciones = np.array(df_modelado['embedding'].tolist())\n",
    "    similitudes = cosine_similarity([embedding_busqueda], embeddings_oraciones)[0]\n",
    "    \n",
    "    # Ordenar las oraciones por similitud\n",
    "    df_modelado['similitud'] = similitudes\n",
    "    resultados = df_modelado[['ep_id', 'sentence_id', 'text', 'similitud']].sort_values(by='similitud', ascending=False).head(top_n)\n",
    "    \n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>similitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63767</th>\n",
       "      <td>95</td>\n",
       "      <td>388</td>\n",
       "      <td>Rework Deep Learning Summit</td>\n",
       "      <td>0.995526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62996</th>\n",
       "      <td>94</td>\n",
       "      <td>522</td>\n",
       "      <td>Reinforcement learning</td>\n",
       "      <td>0.934068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63114</th>\n",
       "      <td>94</td>\n",
       "      <td>640</td>\n",
       "      <td>That's deep learning</td>\n",
       "      <td>0.883056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45215</th>\n",
       "      <td>70</td>\n",
       "      <td>966</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>0.871985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45216</th>\n",
       "      <td>70</td>\n",
       "      <td>967</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>0.871985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ep_id  sentence_id                          text  similitud\n",
       "63767     95          388   Rework Deep Learning Summit   0.995526\n",
       "62996     94          522        Reinforcement learning   0.934068\n",
       "63114     94          640          That's deep learning   0.883056\n",
       "45215     70          966              Machine learning   0.871985\n",
       "45216     70          967              Machine learning   0.871985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Realizar la búsqueda\n",
    "clave_busqueda = \"deep learning\"\n",
    "resultados_busqueda = buscar_por_topico(clave_busqueda, model, df_modelado)\n",
    "\n",
    "resultados_busqueda "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4750111,
     "sourceId": 8200261,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
