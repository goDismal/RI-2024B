{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8200261,"sourceType":"datasetVersion","datasetId":4750111}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:26:31.746736Z","iopub.execute_input":"2025-01-14T14:26:31.747024Z","iopub.status.idle":"2025-01-14T14:26:31.755652Z","shell.execute_reply.started":"2025-01-14T14:26:31.746998Z","shell.execute_reply":"2025-01-14T14:26:31.754634Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lex-fridman-podcast-transcript/podcastdata_dataset.csv\n","output_type":"stream"}],"execution_count":163},{"cell_type":"markdown","source":"Importamos el CSV para empezar a trabajar","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/lex-fridman-podcast-transcript/podcastdata_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:26:35.266553Z","iopub.execute_input":"2025-01-14T14:26:35.266858Z","iopub.status.idle":"2025-01-14T14:26:35.585348Z","shell.execute_reply.started":"2025-01-14T14:26:35.266829Z","shell.execute_reply":"2025-01-14T14:26:35.584562Z"}},"outputs":[],"execution_count":164},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:38:02.891861Z","iopub.execute_input":"2025-01-14T14:38:02.892139Z","iopub.status.idle":"2025-01-14T14:38:02.895616Z","shell.execute_reply.started":"2025-01-14T14:38:02.892118Z","shell.execute_reply":"2025-01-14T14:38:02.894601Z"}},"outputs":[],"execution_count":179},{"cell_type":"markdown","source":"Crear una lista para almacenar las filas del DataFrame final","metadata":{}},{"cell_type":"code","source":"# Crear una lista para almacenar las filas del DataFrame final\nrows = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:38:05.500012Z","iopub.execute_input":"2025-01-14T14:38:05.500324Z","iopub.status.idle":"2025-01-14T14:38:05.538432Z","shell.execute_reply.started":"2025-01-14T14:38:05.500294Z","shell.execute_reply":"2025-01-14T14:38:05.537647Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"# Procesar cada fila del DataFrame\nfor _, row in df.iterrows():\n    text_id = row['id']\n    text = row['text']\n    \n    # Tokenizar el texto en oraciones\n    sentences = [sentence.strip() for sentence in sent_tokenize(text) if sentence.strip()]\n    \n    # Agregar las oraciones al listado con el ID del texto\n    for sentence in sentences:\n        rows.append({'id': text_id, 'oracion': sentence})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:38:07.509046Z","iopub.execute_input":"2025-01-14T14:38:07.509366Z","iopub.status.idle":"2025-01-14T14:38:15.920373Z","shell.execute_reply.started":"2025-01-14T14:38:07.509338Z","shell.execute_reply":"2025-01-14T14:38:15.919564Z"}},"outputs":[],"execution_count":181},{"cell_type":"code","source":"# Crear el nuevo DataFrame\ndf_sentences = pd.DataFrame(rows)\ndf_sentences['tokens'] = df_sentences['oracion'].apply(word_tokenize)\ndf_sentences.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:40:12.631102Z","iopub.execute_input":"2025-01-14T14:40:12.631395Z","iopub.status.idle":"2025-01-14T14:40:56.962164Z","shell.execute_reply.started":"2025-01-14T14:40:12.631373Z","shell.execute_reply":"2025-01-14T14:40:56.961205Z"}},"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"         id                                            oracion  \\\n443537  325                                Is it in the cells?   \n443538  325  There are many, many layers to this as always ...   \n443539  325                    So there are chemical networks.   \n443540  325   So for example, gene regulatory networks, right?   \n443541  325   Which, or basically any kind of chemical pathway   \n\n                                                   tokens  \n443537                        [Is, it, in, the, cells, ?]  \n443538  [There, are, many, ,, many, layers, to, this, ...  \n443539            [So, there, are, chemical, networks, .]  \n443540  [So, for, example, ,, gene, regulatory, networ...  \n443541  [Which, ,, or, basically, any, kind, of, chemi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>oracion</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>443537</th>\n      <td>325</td>\n      <td>Is it in the cells?</td>\n      <td>[Is, it, in, the, cells, ?]</td>\n    </tr>\n    <tr>\n      <th>443538</th>\n      <td>325</td>\n      <td>There are many, many layers to this as always ...</td>\n      <td>[There, are, many, ,, many, layers, to, this, ...</td>\n    </tr>\n    <tr>\n      <th>443539</th>\n      <td>325</td>\n      <td>So there are chemical networks.</td>\n      <td>[So, there, are, chemical, networks, .]</td>\n    </tr>\n    <tr>\n      <th>443540</th>\n      <td>325</td>\n      <td>So for example, gene regulatory networks, right?</td>\n      <td>[So, for, example, ,, gene, regulatory, networ...</td>\n    </tr>\n    <tr>\n      <th>443541</th>\n      <td>325</td>\n      <td>Which, or basically any kind of chemical pathway</td>\n      <td>[Which, ,, or, basically, any, kind, of, chemi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":183},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\n# Crear un modelo Word2Vec\nmodel = Word2Vec(sentences=df_sentences['tokens'], vector_size=100, window=5, min_count=1, workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:43:17.303898Z","iopub.execute_input":"2025-01-14T14:43:17.304172Z","iopub.status.idle":"2025-01-14T14:43:40.114553Z","shell.execute_reply.started":"2025-01-14T14:43:17.304153Z","shell.execute_reply":"2025-01-14T14:43:40.113244Z"}},"outputs":[],"execution_count":186},{"cell_type":"code","source":"import numpy as np\n\n# Función para obtener el embedding promedio de una oración\ndef get_sentence_embedding(tokens, model):\n    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.vector_size)\n\n# Calcular los embeddings para todas las oraciones\ndf_sentences['embedding'] = df_sentences['tokens'].apply(lambda x: get_sentence_embedding(x, model).tolist())\ndf_sentences.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:45:17.782351Z","iopub.execute_input":"2025-01-14T14:45:17.782668Z","iopub.status.idle":"2025-01-14T14:45:44.210533Z","shell.execute_reply.started":"2025-01-14T14:45:17.782648Z","shell.execute_reply":"2025-01-14T14:45:44.209526Z"}},"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"   id                                            oracion  \\\n0   1  As part of MIT course 6S099, Artificial Genera...   \n1   1                     He is a professor here at MIT.   \n2   1  He's a physicist, spent a large part of his ca...   \n3   1  But he's also studied and delved into the bene...   \n4   1  Amongst many other things, he is the cofounder...   \n\n                                              tokens  \\\n0  [As, part, of, MIT, course, 6S099, ,, Artifici...   \n1           [He, is, a, professor, here, at, MIT, .]   \n2  [He, 's, a, physicist, ,, spent, a, large, par...   \n3  [But, he, 's, also, studied, and, delved, into...   \n4  [Amongst, many, other, things, ,, he, is, the,...   \n\n                                           embedding  \n0  [0.17821069061756134, -0.23301361501216888, -0...  \n1  [0.24171370267868042, 0.2438661754131317, -0.4...  \n2  [-0.1599445641040802, 0.7493974566459656, -0.2...  \n3  [0.3598919212818146, 0.46108460426330566, -0.3...  \n4  [0.3858562409877777, 0.6571797132492065, -0.42...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>oracion</th>\n      <th>tokens</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n      <td>[As, part, of, MIT, course, 6S099, ,, Artifici...</td>\n      <td>[0.17821069061756134, -0.23301361501216888, -0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>He is a professor here at MIT.</td>\n      <td>[He, is, a, professor, here, at, MIT, .]</td>\n      <td>[0.24171370267868042, 0.2438661754131317, -0.4...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>He's a physicist, spent a large part of his ca...</td>\n      <td>[He, 's, a, physicist, ,, spent, a, large, par...</td>\n      <td>[-0.1599445641040802, 0.7493974566459656, -0.2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>But he's also studied and delved into the bene...</td>\n      <td>[But, he, 's, also, studied, and, delved, into...</td>\n      <td>[0.3598919212818146, 0.46108460426330566, -0.3...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Amongst many other things, he is the cofounder...</td>\n      <td>[Amongst, many, other, things, ,, he, is, the,...</td>\n      <td>[0.3858562409877777, 0.6571797132492065, -0.42...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":190},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# Cargar los embeddings\nembeddings = np.array(df_sentences['embedding'].tolist())\n\n# Aplicar KMeans para clusterización\nnum_clusters = 5  # Define el número de clusters según el caso\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ndf_sentences['cluster'] = kmeans.fit_predict(embeddings)\ndf_sentences.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:47:41.045575Z","iopub.execute_input":"2025-01-14T14:47:41.045844Z","iopub.status.idle":"2025-01-14T14:48:14.699064Z","shell.execute_reply.started":"2025-01-14T14:47:41.045825Z","shell.execute_reply":"2025-01-14T14:48:14.698013Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"   id                                            oracion  \\\n0   1  As part of MIT course 6S099, Artificial Genera...   \n1   1                     He is a professor here at MIT.   \n2   1  He's a physicist, spent a large part of his ca...   \n3   1  But he's also studied and delved into the bene...   \n4   1  Amongst many other things, he is the cofounder...   \n\n                                              tokens  \\\n0  [As, part, of, MIT, course, 6S099, ,, Artifici...   \n1           [He, is, a, professor, here, at, MIT, .]   \n2  [He, 's, a, physicist, ,, spent, a, large, par...   \n3  [But, he, 's, also, studied, and, delved, into...   \n4  [Amongst, many, other, things, ,, he, is, the,...   \n\n                                           embedding  cluster  \n0  [0.17821069061756134, -0.23301361501216888, -0...        0  \n1  [0.24171370267868042, 0.2438661754131317, -0.4...        0  \n2  [-0.1599445641040802, 0.7493974566459656, -0.2...        0  \n3  [0.3598919212818146, 0.46108460426330566, -0.3...        0  \n4  [0.3858562409877777, 0.6571797132492065, -0.42...        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>oracion</th>\n      <th>tokens</th>\n      <th>embedding</th>\n      <th>cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n      <td>[As, part, of, MIT, course, 6S099, ,, Artifici...</td>\n      <td>[0.17821069061756134, -0.23301361501216888, -0...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>He is a professor here at MIT.</td>\n      <td>[He, is, a, professor, here, at, MIT, .]</td>\n      <td>[0.24171370267868042, 0.2438661754131317, -0.4...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>He's a physicist, spent a large part of his ca...</td>\n      <td>[He, 's, a, physicist, ,, spent, a, large, par...</td>\n      <td>[-0.1599445641040802, 0.7493974566459656, -0.2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>But he's also studied and delved into the bene...</td>\n      <td>[But, he, 's, also, studied, and, delved, into...</td>\n      <td>[0.3598919212818146, 0.46108460426330566, -0.3...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Amongst many other things, he is the cofounder...</td>\n      <td>[Amongst, many, other, things, ,, he, is, the,...</td>\n      <td>[0.3858562409877777, 0.6571797132492065, -0.42...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":192},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n# Consulta de ejemplo\nquery = \"artificial intelligence\"\nquery_tokens = word_tokenize(query.lower())  # Tokenizar la consulta\n\n# Calcular el embedding de la consulta\nquery_embedding = get_sentence_embedding(query_tokens, model).reshape(1, -1)\n\n# Calcular similitudes entre la consulta y los embeddings de las oraciones\ndf_sentences['similarity'] = df_sentences['embedding'].apply(lambda x: cosine_similarity(query_embedding, np.array(x).reshape(1, -1))[0][0])\n\n# Ordenar las oraciones por similitud (de mayor a menor)\nresultados = df.sort_values(by='similarity', ascending=False)\n\n# Mostrar las oraciones más relevantes\nprint(resultados[['id', 'oracion', 'similarity']].head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:52:40.977409Z","iopub.execute_input":"2025-01-14T14:52:40.977698Z","iopub.status.idle":"2025-01-14T14:53:59.864980Z","shell.execute_reply.started":"2025-01-14T14:52:40.977679Z","shell.execute_reply":"2025-01-14T14:53:59.863860Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-196-fe22f3fadee0>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Ordenar las oraciones por similitud (de mayor a menor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresultados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'similarity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Mostrar las oraciones más relevantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6942\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6944\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6946\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'similarity'"],"ename":"KeyError","evalue":"'similarity'","output_type":"error"}],"execution_count":196}]}